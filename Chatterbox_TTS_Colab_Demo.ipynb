{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcQFeUm-0tY6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Setup and Installation (Robust Version)\n",
        "# Clone repository and install dependencies with error handling\n",
        "\n",
        "# Remove existing directory and clear cache\n",
        "!rm -rf Chatterbox-TTS-Server\n",
        "!pip cache purge\n",
        "\n",
        "# Clone repository\n",
        "!git clone https://github.com/devnen/Chatterbox-TTS-Server.git\n",
        "%cd Chatterbox-TTS-Server\n",
        "\n",
        "print(\"✅ Repository cloned. Installing core dependencies...\")\n",
        "\n",
        "# Install PyTorch with compatible torchvision\n",
        "!pip install torch==2.5.1+cu121 torchaudio==2.5.1+cu121 torchvision==0.20.1+cu121 --index-url https://download.pytorch.org/whl/cu121 -q\n",
        "\n",
        "# Install your Colab-compatible chatterbox fork\n",
        "!pip install git+https://github.com/devnen/chatterbox.git -q\n",
        "\n",
        "print(\"✅ Core TTS components installed. Installing server dependencies...\")\n",
        "\n",
        "# Install essential server requirements (skip problematic packages)\n",
        "!pip install fastapi uvicorn pyyaml soundfile librosa safetensors -q\n",
        "!pip install python-multipart requests jinja2 watchdog aiofiles unidecode inflect tqdm -q\n",
        "!pip install pydub audiotsm -q\n",
        "\n",
        "# Try to install parselmouth (may fail on some systems)\n",
        "!pip install parselmouth -q || echo \"Parselmouth installation failed - unvoiced segment removal will be disabled\"\n",
        "\n",
        "print(\"✅ Installation complete! Some optional packages may have been skipped.\")"
      ],
      "metadata": {
        "id": "3ghls0ts1PH_",
        "outputId": "3c63531d-0ef5-4d9a-b5a1-388ca562cdd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
            "\u001b[0mFiles removed: 0\n",
            "Cloning into 'Chatterbox-TTS-Server'...\n",
            "remote: Enumerating objects: 302, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 302 (delta 138), reused 119 (delta 119), pack-reused 139 (from 1)\u001b[K\n",
            "Receiving objects: 100% (302/302), 18.94 MiB | 17.04 MiB/s, done.\n",
            "Resolving deltas: 100% (147/147), done.\n",
            "/content/Chatterbox-TTS-Server\n",
            "✅ Repository cloned. Installing core dependencies...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m798.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m130.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.3/664.8 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:38\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import torchaudio as ta\n",
        "from chatterbox.tts import ChatterboxTTS\n",
        "from chatterbox.mtl_tts import ChatterboxMultilingualTTS\n",
        "import re\n",
        "\n",
        "# Il tuo monkey patch per torch.load\n",
        "original_torch_load = torch.load\n",
        "\n",
        "def patched_torch_load(f, map_location=None, **kwargs):\n",
        "    if map_location is None:\n",
        "        map_location = 'cpu'\n",
        "    return original_torch_load(f, map_location=map_location, **kwargs)\n",
        "\n",
        "torch.load = patched_torch_load\n",
        "if 'torch' in sys.modules:\n",
        "    sys.modules['torch'].load = patched_torch_load\n",
        "\n",
        "device = \"cpu\"\n",
        "multilingual_model = ChatterboxMultilingualTTS.from_pretrained(device=device)\n",
        "\n",
        "# Funzione per dividere il dialogo\n",
        "def parse_dialogue(text):\n",
        "    \"\"\"\n",
        "    Divide il testo del dialogo in speaker e battute\n",
        "    \"\"\"\n",
        "    # Pattern per riconoscere i cambi di speaker (assumendo punteggiatura come indicatore)\n",
        "    sentences = re.split(r'[.!?]+', text.strip())\n",
        "\n",
        "    # Lista per contenere i segmenti di dialogo\n",
        "    dialogue_parts = []\n",
        "    current_speaker = \"speaker1\"\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        if sentence.strip():\n",
        "            # Alterna tra speaker1 e speaker2 basandosi su parole chiave o punteggiatura\n",
        "            if any(word in sentence.lower() for word in [\"pronto\", \"buongiorno\", \"sì\", \"perfetto\", \"bene\"]):\n",
        "                if i % 2 == 0:\n",
        "                    current_speaker = \"speaker1\"  # Operatore CUP\n",
        "                else:\n",
        "                    current_speaker = \"speaker2\"  # Cliente\n",
        "            else:\n",
        "                # Alterna automaticamente\n",
        "                current_speaker = \"speaker1\" if i % 2 == 0 else \"speaker2\"\n",
        "\n",
        "            dialogue_parts.append({\n",
        "                'speaker': current_speaker,\n",
        "                'text': sentence.strip() + \".\"\n",
        "            })\n",
        "\n",
        "    return dialogue_parts\n",
        "\n",
        "# Metodo migliorato: divisione manuale del dialogo\n",
        "def create_manual_dialogue():\n",
        "    \"\"\"\n",
        "    Crea manualmente la divisione del dialogo per maggiore controllo\n",
        "    \"\"\"\n",
        "    dialogue = [\n",
        "        {\"speaker\": \"operator\", \"text\": \"Pronto, CUP, buongiorno come posso aiutarla?\"},\n",
        "        {\"speaker\": \"client\", \"text\": \"Buongiorno, senta io avrei bisogno di prenotare una visita neurologica.\"},\n",
        "        {\"speaker\": \"operator\", \"text\": \"Certo, mi può dire il suo nome e cognome per favore?\"},\n",
        "        {\"speaker\": \"client\", \"text\": \"Sì, sono Mario Bianchi.\"},\n",
        "        {\"speaker\": \"operator\", \"text\": \"Perfetto signor Bianchi, ora mi serve il suo codice fiscale.\"},\n",
        "        {\"speaker\": \"client\", \"text\": \"Allora... B-I-A-N-C-O... no scusi, B-I-A-N-C-H-I come Bari, M-A-R-I-O come Milano, settantadue... aspetti che controllo... settantadue, A come Ancona, zero-uno, L come Livorno, seicentoventisette, G come Genova.\"},\n",
        "        {\"speaker\": \"operator\", \"text\": \"Quindi BNCMRA72A01L627G, corretto?\"},\n",
        "        {\"speaker\": \"client\", \"text\": \"Sì esatto.\"},\n",
        "        {\"speaker\": \"operator\", \"text\": \"Bene, per quale motivo ha bisogno della visita neurologica? Ha una impegnativa del medico di base?\"},\n",
        "        {\"speaker\": \"client\", \"text\": \"Sì ce l'ho, è per dei mal di testa ricorrenti che ho da qualche mese, il dottore mi ha consigliato di fare una visita di controllo.\"},\n",
        "        # Continua con il resto del dialogo...\n",
        "    ]\n",
        "    return dialogue\n",
        "\n",
        "# Genera la conversazione\n",
        "def generate_conversation():\n",
        "    \"\"\"\n",
        "    Genera l'audio della conversazione con due voci diverse\n",
        "    \"\"\"\n",
        "    dialogue = create_manual_dialogue()\n",
        "\n",
        "    # Path per i file audio di riferimento (voci diverse)\n",
        "    OPERATOR_VOICE = \"registrazione.wav\"  # Voce dell'operatore\n",
        "    CLIENT_VOICE = \"registrazione.wav\"    # Stessa voce per ora, puoi cambiare\n",
        "\n",
        "    audio_segments = []\n",
        "\n",
        "    for i, turn in enumerate(dialogue):\n",
        "        print(f\"Generando: {turn['speaker']} - {turn['text'][:50]}...\")\n",
        "\n",
        "        # Scegli il prompt audio basandoti sul speaker\n",
        "        if turn['speaker'] == \"operator\":\n",
        "            audio_prompt = OPERATOR_VOICE\n",
        "        else:\n",
        "            audio_prompt = CLIENT_VOICE\n",
        "\n",
        "        # Genera l'audio per questa battuta\n",
        "        wav = multilingual_model.generate(\n",
        "            turn['text'],\n",
        "            audio_prompt_path=audio_prompt,\n",
        "            language_id=\"it\"\n",
        "        )\n",
        "\n",
        "        # Salva il segmento individuale\n",
        "        segment_filename = f\"segment_{i:02d}_{turn['speaker']}.wav\"\n",
        "        ta.save(segment_filename, wav, multilingual_model.sr)\n",
        "        audio_segments.append(wav)\n",
        "\n",
        "    return audio_segments\n",
        "\n",
        "# Funzione per concatenare i segmenti audio\n",
        "def concatenate_audio_segments(segments):\n",
        "    \"\"\"\n",
        "    Concatena tutti i segmenti audio in un unico file\n",
        "    \"\"\"\n",
        "    import torch\n",
        "\n",
        "    # Aggiungi pause tra i segmenti\n",
        "    pause_duration = int(0.5 * multilingual_model.sr)  # 0.5 secondi di pausa\n",
        "    pause = torch.zeros(1, pause_duration)\n",
        "\n",
        "    full_audio = []\n",
        "    for i, segment in enumerate(segments):\n",
        "        full_audio.append(segment)\n",
        "        if i < len(segments) - 1:  # Non aggiungere pausa dopo l'ultimo segmento\n",
        "            full_audio.append(pause)\n",
        "\n",
        "    # Concatena tutto\n",
        "    final_audio = torch.cat(full_audio, dim=1)\n",
        "    return final_audio\n",
        "\n",
        "# Esegui la generazione\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generando conversazione...\")\n",
        "    segments = generate_conversation()\n",
        "\n",
        "    print(\"Concatenando segmenti...\")\n",
        "    final_conversation = concatenate_audio_segments(segments)\n",
        "\n",
        "    print(\"Salvando conversazione completa...\")\n",
        "    ta.save(\"conversazione_completa.wav\", final_conversation, multilingual_model.sr)\n",
        "    print(\"Conversazione salvata come 'conversazione_completa.wav'\")\n"
      ],
      "metadata": {
        "id": "Wm_FHPwV1Zkx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}